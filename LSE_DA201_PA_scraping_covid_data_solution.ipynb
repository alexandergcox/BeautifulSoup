{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75a9832",
   "metadata": {},
   "source": [
    "### LSE Data Analytics Online Career Accelerator\n",
    "\n",
    "# DA201: Data Analytics using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963426a8",
   "metadata": {},
   "source": [
    "## Practical activity: Scraping COVID data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615e7ee",
   "metadata": {},
   "source": [
    "**This is the solution to the activity.**\n",
    "\n",
    "You work as a data analyst at a health insurance company. To provide up-to-date information for the executive, claims department, and clients, you are tasked with gathering the latest data on worldwide COVID-19 cases. \n",
    "\n",
    "Each department requires different information. For each continent on the list:\n",
    "The executive needs to know:\n",
    "- Total cases\n",
    "- Total deaths\n",
    "\n",
    "Claims needs to know:\n",
    "- New cases\n",
    "- New deaths\n",
    "- Active cases\n",
    "- Serious, Critical\n",
    "\n",
    "Clients need to know:\n",
    "- Total cases\n",
    "- Total recovered\n",
    "- Newly recovered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb962e25",
   "metadata": {},
   "source": [
    "## 1. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde628ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages.\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a538ea",
   "metadata": {},
   "source": [
    "## 2. Establish connection with URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998dcb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a url variable.\n",
    "url = 'https://www.worldometers.info/coronavirus/'\n",
    "\n",
    "# Create a requests variable.\n",
    "r = requests.get(url)\n",
    "\n",
    "# Make contact with the website.\n",
    "if r.status_code == 200:\n",
    "    html_doc = r.text\n",
    "    \n",
    "# Get a BeautifulSoup object.\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the output.\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53503590",
   "metadata": {},
   "source": [
    "## 3. Extract tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the contents of the table with the table id. \n",
    "table = soup.find('table', attrs={'id': 'main_table_countries_today'})\n",
    "\n",
    "# View the table.\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06d215",
   "metadata": {},
   "source": [
    "## 4. Extract table headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fbe1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify BeautifulSoup to go through the table and find everything \n",
    "# with a tr tag.\n",
    "# Note: th = (table header), tr = (table row), and td = table column\n",
    "rows = table.find_all('tr', attrs={'style': \"\"})\n",
    "\n",
    "# View the result.\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905143d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the extracted data.\n",
    "output = []\n",
    "\n",
    "column_names = ['Country,Other', 'Total Cases', 'New Cases', 'Total Deaths',\n",
    "               'New Deaths', 'Total Recovered', 'New Recovered',\n",
    "               'Active Cases', 'Serious, Critical', 'Tot Cases/ 1M pop',\n",
    "               'Deaths/ 1M pop', 'Total Tests', 'Tests/ 1M pop', 'Population']\n",
    "\n",
    "# Create a for loop statement.\n",
    "for cases in rows:\n",
    "    cases_data = cases.find_all(\"td\")\n",
    "    if cases_data:\n",
    "        # Extract the text within each element.\n",
    "        cases_text = [td.text for td in cases_data]\n",
    "        output.append(dict(zip(column_names, cases_text)))\n",
    "        \n",
    "# Create an output.\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5921ef5",
   "metadata": {},
   "source": [
    "## 5. Convert extracted data into a Panda DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8759845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame directly from the output.\n",
    "data = pd.DataFrame(output)\n",
    "\n",
    "# View the DataFrame.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad175a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
