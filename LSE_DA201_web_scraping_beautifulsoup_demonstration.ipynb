{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c017c5",
   "metadata": {},
   "source": [
    "### LSE Data Analytics Online Career Accelerator\n",
    "\n",
    "# DA201: Data Analytics using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677598c2",
   "metadata": {},
   "source": [
    "## Web scraping with BeautifulSoup (tutorial video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c16e2",
   "metadata": {},
   "source": [
    "Web scraping or web harvesting is frequently used by data analysts to retrieve current data. BeautifulSoup is a popular Python library for web scraping. This Notebook will illustrate step-by-step how to perform web scraping with BeautifulSoup, convert the extracted data into a CSV file, and construct a Pandas DataFrame. You will learn:\n",
    "- Performing web scraping with BeautifulSoup.\n",
    "- Saving extracted data as JSON and CSV files.\n",
    "- Import the extracted data into a Pandas DataFrame for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ff7c9",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf174db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries.\n",
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af672e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "# Analyse the data.\n",
    "import pandas as pd\n",
    "\n",
    "# Get data from the internet.\n",
    "import requests\n",
    "\n",
    "# Parse data with BeautifulSoup.\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6dcfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the url.\n",
    "# Create a variable to store the URL.\n",
    "url = 'https://www.worldometers.info/world-population/population-by-country/'\n",
    "\n",
    "# Create a vairable to store the information.\n",
    "page = requests.get(url)\n",
    "\n",
    "# Make contact with the website.\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ff3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the information from the website.\n",
    "if page.status_code == 200:\n",
    "    html_doc = page.text\n",
    "\n",
    "# Look at the html code.\n",
    "# Create a variable to store the HTML info.\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the output in a readable format.\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2bc0b6",
   "metadata": {},
   "source": [
    "##  Extract table ID from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df37481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the website and determine the table ID.\n",
    "# Extract the contents of the table with the table ID.\n",
    "table = soup.find('table', attrs={'id': 'example2'})\n",
    "\n",
    "# View the information in a readable format.\n",
    "print(table.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63453e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the rows of the table.\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# View the rows.\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the extracted data.\n",
    "# Create an empty list.\n",
    "output = []\n",
    "\n",
    "# Specify the column names.\n",
    "column_names = ['ID', 'Country (or dependency)', 'Population (2020)',\n",
    "                'Yearly Change', 'Net Change', 'Density (P/Km2)',\n",
    "                'Land Area (Km2)', 'Migrants (net)', 'Fert. Rate',\n",
    "                'Med. Age', 'Urbn Pop', 'World Share']\n",
    "\n",
    "# Create a for loop statement.\n",
    "for country in rows:\n",
    "    country_data = country.find_all('td')\n",
    "    if country_data:\n",
    "        # Extract the text within each element.\n",
    "        country_text = [td.text for td in country_data]\n",
    "        # Store data in a zip format for easy access.\n",
    "        output.append(dict(zip(column_names, country_text)))\n",
    "        \n",
    "# View the result.\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5685b8b",
   "metadata": {},
   "source": [
    "## Create a CSV or JSON file and import into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b82b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame directly from the output.\n",
    "data = pd.DataFrame(output)\n",
    "\n",
    "# View the DataFrame.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file without index.\n",
    "data.to_csv('countries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a JSON file.\n",
    "import json\n",
    "\n",
    "# Create a JSON file.\n",
    "output_json = json.dumps(output)\n",
    "\n",
    "# View the output.\n",
    "output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the JSON file to .json.\n",
    "with open('countries.json', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83390fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON using Pandas, output to .csv.\n",
    "pd.read_json(output_json).to_csv('countries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c3d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CSV file with Pandas.\n",
    "# Data = pd.read_json('countries.json').\n",
    "data = pd.read_csv('countries.csv')\n",
    "\n",
    "# View.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e871e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON file with Pandas.\n",
    "data = pd.read_json('countries.json')\n",
    "\n",
    "# View the DataFrame.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e55920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
